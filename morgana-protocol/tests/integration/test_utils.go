//go:build integration
// +build integration

package integration

import (
	"context"
	"fmt"
	"math/rand"
	"os"
	"sync"
	"sync/atomic"
	"testing"
	"time"

	"github.com/saintskeeper/claude-code-configs/morgana-protocol/internal/events"
)

// TestEventGenerator generates test events for integration testing
type TestEventGenerator struct {
	eventBus events.EventBus
	taskIDs  []string
	counter  int64
	mu       sync.Mutex
}

// NewTestEventGenerator creates a new test event generator
func NewTestEventGenerator(eventBus events.EventBus) *TestEventGenerator {
	return &TestEventGenerator{
		eventBus: eventBus,
		taskIDs:  make([]string, 0),
	}
}

// GenerateTaskLifecycle generates a complete task lifecycle (start -> progress -> complete)
func (g *TestEventGenerator) GenerateTaskLifecycle(ctx context.Context, agentType string, delay time.Duration) string {
	taskID := g.generateTaskID()

	// Task started event
	startEvent := events.NewTaskStartedEvent(
		ctx, taskID, agentType,
		fmt.Sprintf("Test prompt for %s", agentType),
		map[string]interface{}{"test": true, "agent": agentType},
		0, "test-model-hint", "medium", time.Minute*2,
	)
	g.eventBus.PublishAsync(startEvent)

	// Progress events with delay
	go func() {
		stages := []string{"validation", "prompt_load", "execution"}
		for i, stage := range stages {
			time.Sleep(delay)
			progress := float64(i+1) / float64(len(stages))

			progressEvent := events.NewTaskProgressEvent(
				ctx, taskID, agentType, stage,
				fmt.Sprintf("Processing %s stage", stage),
				progress, time.Duration(i+1)*delay,
			)
			g.eventBus.PublishAsync(progressEvent)
		}

		// Complete event
		time.Sleep(delay)
		completeEvent := events.NewTaskCompletedEvent(
			ctx, taskID, agentType,
			fmt.Sprintf("Task %s completed successfully", taskID),
			time.Duration(len(stages)+1)*delay,
			"claude-3-5-sonnet-20241022",
		)
		g.eventBus.PublishAsync(completeEvent)
	}()

	return taskID
}

// GenerateFailedTask generates a failed task scenario
func (g *TestEventGenerator) GenerateFailedTask(ctx context.Context, agentType string, delay time.Duration) string {
	taskID := g.generateTaskID()

	startEvent := events.NewTaskStartedEvent(
		ctx, taskID, agentType,
		fmt.Sprintf("Test prompt for failing %s", agentType),
		map[string]interface{}{"test": true, "should_fail": true},
		1, "", "high", time.Minute,
	)
	g.eventBus.PublishAsync(startEvent)

	go func() {
		time.Sleep(delay)
		progressEvent := events.NewTaskProgressEvent(
			ctx, taskID, agentType, "execution",
			"Processing task...", 0.3, delay,
		)
		g.eventBus.PublishAsync(progressEvent)

		time.Sleep(delay)
		failedEvent := events.NewTaskFailedEvent(
			ctx, taskID, agentType,
			"Simulated task failure for testing",
			delay*2, "execution", 1,
		)
		g.eventBus.PublishAsync(failedEvent)
	}()

	return taskID
}

// GenerateHighVolumeEvents generates many events quickly for performance testing
func (g *TestEventGenerator) GenerateHighVolumeEvents(ctx context.Context, count int, agentTypes []string) []string {
	var taskIDs []string

	for i := 0; i < count; i++ {
		agentType := agentTypes[i%len(agentTypes)]
		taskID := g.generateTaskID()
		taskIDs = append(taskIDs, taskID)

		event := events.NewTaskStartedEvent(
			ctx, taskID, agentType,
			fmt.Sprintf("High volume test event %d", i),
			map[string]interface{}{"index": i, "bulk_test": true},
			0, "", "low", time.Second*30,
		)

		if !g.eventBus.PublishAsync(event) {
			// Event was dropped - this is expected under high load
		}
	}

	return taskIDs
}

func (g *TestEventGenerator) generateTaskID() string {
	g.mu.Lock()
	defer g.mu.Unlock()

	counter := atomic.AddInt64(&g.counter, 1)
	taskID := fmt.Sprintf("test-task-%d-%d", time.Now().UnixNano(), counter)
	g.taskIDs = append(g.taskIDs, taskID)
	return taskID
}

// GetGeneratedTaskIDs returns all task IDs generated by this generator
func (g *TestEventGenerator) GetGeneratedTaskIDs() []string {
	g.mu.Lock()
	defer g.mu.Unlock()
	return append([]string(nil), g.taskIDs...)
}

// EventCollector collects events for testing and analysis
type EventCollector struct {
	events    []events.Event
	mu        sync.RWMutex
	startTime time.Time
	stats     CollectorStats
}

type CollectorStats struct {
	TotalEvents     int64                    `json:"total_events"`
	EventsByType    map[events.EventType]int `json:"events_by_type"`
	EventsByAgent   map[string]int           `json:"events_by_agent"`
	FirstEventTime  time.Time                `json:"first_event_time"`
	LastEventTime   time.Time                `json:"last_event_time"`
	ProcessingTimes []time.Duration          `json:"processing_times"`
}

// NewEventCollector creates a new event collector
func NewEventCollector() *EventCollector {
	return &EventCollector{
		events:    make([]events.Event, 0),
		startTime: time.Now(),
		stats: CollectorStats{
			EventsByType:  make(map[events.EventType]int),
			EventsByAgent: make(map[string]int),
		},
	}
}

// CollectEvent collects an event and updates statistics
func (c *EventCollector) CollectEvent(event events.Event) {
	c.mu.Lock()
	defer c.mu.Unlock()

	c.events = append(c.events, event)
	atomic.AddInt64(&c.stats.TotalEvents, 1)

	c.stats.EventsByType[event.Type()]++

	// Extract agent type from event if possible
	agentType := c.extractAgentType(event)
	if agentType != "" {
		c.stats.EventsByAgent[agentType]++
	}

	// Update timing stats
	now := time.Now()
	if c.stats.FirstEventTime.IsZero() {
		c.stats.FirstEventTime = now
	}
	c.stats.LastEventTime = now

	processingTime := now.Sub(event.Timestamp())
	c.stats.ProcessingTimes = append(c.stats.ProcessingTimes, processingTime)
}

// extractAgentType extracts agent type from different event types
func (c *EventCollector) extractAgentType(event events.Event) string {
	switch e := event.(type) {
	case *events.TaskStartedEvent:
		return e.AgentType
	case *events.TaskProgressEvent:
		return e.AgentType
	case *events.TaskCompletedEvent:
		return e.AgentType
	case *events.TaskFailedEvent:
		return e.AgentType
	default:
		return ""
	}
}

// GetStats returns current statistics
func (c *EventCollector) GetStats() CollectorStats {
	c.mu.RLock()
	defer c.mu.RUnlock()

	// Calculate average processing time
	if len(c.stats.ProcessingTimes) > 0 {
		var total time.Duration
		for _, pt := range c.stats.ProcessingTimes {
			total += pt
		}
		// Could add average processing time to stats if needed
	}

	return c.stats
}

// GetEvents returns collected events (thread-safe copy)
func (c *EventCollector) GetEvents() []events.Event {
	c.mu.RLock()
	defer c.mu.RUnlock()

	eventsCopy := make([]events.Event, len(c.events))
	copy(eventsCopy, c.events)
	return eventsCopy
}

// GetEventsOfType returns events of a specific type
func (c *EventCollector) GetEventsOfType(eventType events.EventType) []events.Event {
	c.mu.RLock()
	defer c.mu.RUnlock()

	var filtered []events.Event
	for _, event := range c.events {
		if event.Type() == eventType {
			filtered = append(filtered, event)
		}
	}
	return filtered
}

// GetEventsForTask returns all events for a specific task ID
func (c *EventCollector) GetEventsForTask(taskID string) []events.Event {
	c.mu.RLock()
	defer c.mu.RUnlock()

	var taskEvents []events.Event
	for _, event := range c.events {
		if event.TaskID() == taskID {
			taskEvents = append(taskEvents, event)
		}
	}
	return taskEvents
}

// Reset clears all collected events and stats
func (c *EventCollector) Reset() {
	c.mu.Lock()
	defer c.mu.Unlock()

	c.events = c.events[:0] // Clear slice but keep capacity
	c.stats = CollectorStats{
		EventsByType:  make(map[events.EventType]int),
		EventsByAgent: make(map[string]int),
	}
	atomic.StoreInt64(&c.stats.TotalEvents, 0)
}

// TestSetup contains common test setup
type TestSetup struct {
	EventBus    events.EventBus
	Collector   *EventCollector
	Generator   *TestEventGenerator
	MonitorSock string
	TempDir     string
	Cleanup     func()
}

// SetupIntegrationTest creates a complete test environment
func SetupIntegrationTest(t *testing.T) *TestSetup {
	// Create event bus with optimized config for testing
	config := events.DefaultBusConfig()
	config.BufferSize = 5000         // Larger buffer for high-volume tests
	config.Workers = 8               // More workers for parallel processing
	config.Debug = testing.Verbose() // Enable debug if verbose testing

	eventBus := events.NewEventBus(config)

	// Create collector and subscribe to all events
	collector := NewEventCollector()
	subscriptionID := eventBus.SubscribeAll(collector.CollectEvent)

	// Create generator
	generator := NewTestEventGenerator(eventBus)

	// Create temporary directory and socket path
	tempDir, err := os.MkdirTemp("", "morgana-integration-*")
	if err != nil {
		t.Fatalf("Failed to create temp directory: %v", err)
	}

	monitorSock := tempDir + "/monitor.sock"

	setup := &TestSetup{
		EventBus:    eventBus,
		Collector:   collector,
		Generator:   generator,
		MonitorSock: monitorSock,
		TempDir:     tempDir,
		Cleanup: func() {
			eventBus.Unsubscribe(subscriptionID)
			eventBus.Close()
			os.RemoveAll(tempDir)
		},
	}

	return setup
}

// PerformanceAssertions contains performance test thresholds
type PerformanceAssertions struct {
	MaxEventLatency     time.Duration // Maximum time from event creation to processing
	MinThroughput       float64       // Minimum events per second
	MaxMemoryUsageMB    float64       // Maximum memory usage in MB
	MaxDroppedEventRate float64       // Maximum percentage of dropped events (0.0-1.0)
}

// DefaultPerformanceAssertions returns reasonable performance expectations
func DefaultPerformanceAssertions() PerformanceAssertions {
	return PerformanceAssertions{
		MaxEventLatency:     10 * time.Millisecond, // <10ms requirement
		MinThroughput:       10000,                 // 10k events/sec minimum
		MaxMemoryUsageMB:    100,                   // 100MB max memory
		MaxDroppedEventRate: 0.01,                  // 1% max dropped events
	}
}

// AssertPerformance checks if performance meets expectations
func AssertPerformance(t *testing.T, stats CollectorStats, busStats events.BusStats, assertions PerformanceAssertions) {
	// Check event latency
	if len(stats.ProcessingTimes) > 0 {
		var maxLatency time.Duration
		var totalLatency time.Duration

		for _, latency := range stats.ProcessingTimes {
			if latency > maxLatency {
				maxLatency = latency
			}
			totalLatency += latency
		}

		avgLatency := totalLatency / time.Duration(len(stats.ProcessingTimes))

		if maxLatency > assertions.MaxEventLatency {
			t.Errorf("Maximum event latency too high: %v (max allowed: %v)",
				maxLatency, assertions.MaxEventLatency)
		}

		t.Logf("Event latency - Max: %v, Avg: %v", maxLatency, avgLatency)
	}

	// Check throughput
	if !stats.FirstEventTime.IsZero() && !stats.LastEventTime.IsZero() {
		duration := stats.LastEventTime.Sub(stats.FirstEventTime)
		if duration > 0 {
			throughput := float64(stats.TotalEvents) / duration.Seconds()
			if throughput < assertions.MinThroughput {
				t.Errorf("Throughput too low: %.0f events/sec (min required: %.0f)",
					throughput, assertions.MinThroughput)
			}
			t.Logf("Event throughput: %.0f events/sec", throughput)
		}
	}

	// Check dropped events
	if busStats.TotalPublished > 0 {
		dropRate := float64(busStats.TotalDropped) / float64(busStats.TotalPublished)
		if dropRate > assertions.MaxDroppedEventRate {
			t.Errorf("Dropped event rate too high: %.2f%% (max allowed: %.2f%%)",
				dropRate*100, assertions.MaxDroppedEventRate*100)
		}
		t.Logf("Event drop rate: %.2f%%", dropRate*100)
	}

	t.Logf("Bus stats - Published: %d, Dropped: %d, Queue: %d/%d",
		busStats.TotalPublished, busStats.TotalDropped,
		busStats.QueueSize, busStats.QueueCapacity)
}

// RandomAgentTypes returns a list of agent types for testing
func RandomAgentTypes() []string {
	return []string{
		"code-implementer",
		"test-specialist",
		"validation-expert",
		"sprint-planner",
		"documentation-writer",
		"architecture-reviewer",
	}
}

// WaitForEvents waits for a specific number of events to be collected
func WaitForEvents(collector *EventCollector, expectedCount int, timeout time.Duration) bool {
	deadline := time.Now().Add(timeout)
	for time.Now().Before(deadline) {
		stats := collector.GetStats()
		if int(stats.TotalEvents) >= expectedCount {
			return true
		}
		time.Sleep(10 * time.Millisecond)
	}
	return false
}

// WaitForEventType waits for a specific type of event to be collected
func WaitForEventType(collector *EventCollector, eventType events.EventType, timeout time.Duration) bool {
	deadline := time.Now().Add(timeout)
	for time.Now().Before(deadline) {
		events := collector.GetEventsOfType(eventType)
		if len(events) > 0 {
			return true
		}
		time.Sleep(10 * time.Millisecond)
	}
	return false
}

// SimulateResourceConstraints simulates system resource constraints for testing
func SimulateResourceConstraints() {
	// Simulate CPU load by doing some work
	go func() {
		for i := 0; i < 1000; i++ {
			rand.Float64()
			time.Sleep(time.Microsecond)
		}
	}()

	// Brief pause to simulate memory pressure
	time.Sleep(time.Millisecond)
}
